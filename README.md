# ml-practice-lgbm-catboost
Practice comparing Random Forest, LightGBM, and CatBoost on the Titanic dataset.
# Titanic Ensemble Models

This project demonstrates how to compare classic ensemble methods â€” **Random Forest**, **LightGBM**, and **CatBoost** â€” on the famous **Titanic dataset**.

## ğŸ“Š Whatâ€™s inside?

- ğŸ—‚ï¸ Clean Titanic dataset
- âœ… Feature engineering (Title, Cabin, Embarked, etc.)
- ğŸ” Model training:
  - Random Forest (Bagging)
  - LightGBM (Boosting)
  - CatBoost (Boosting, automatic categorical handling)
- ğŸ“ˆ Feature importance comparison (Split vs Gain)
- âš™ï¸ Cross-validation
- ğŸ”® Submission file generation (optional)

## ğŸš€ How to run

1. **Create Conda environment:**

    ```bash
    conda create -n titanic-ml python=3.9
    conda activate titanic-ml
    ```

2. **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

3. **Start Jupyter Notebook:**

    ```bash
    jupyter notebook
    ```

4. **Open `titanic_ensemble.ipynb` and run step by step.**

## âš™ï¸ Dependencies

See `requirements.txt`.

## ğŸ“„ License

This project is licensed under the MIT License.
